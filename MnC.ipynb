{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPAdhoLt0JB9",
    "outputId": "c11a6af5-b2fe-4e81-9def-4cfab5c76224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ui-60BZ6qInY",
    "outputId": "d18bce76-8149-446d-d6b2-5e37528381cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Y2OwZZzq5bjfWu3Vo3Par_auQxCGt6ze\n",
      "To: /content/m.zip\n",
      "\r",
      "  0% 0.00/645k [00:00<?, ?B/s]\r",
      "100% 645k/645k [00:00<00:00, 10.2MB/s]\n",
      "Archive:  m.zip\n",
      "   creating: agents/\n",
      "  inflating: agents/DQNNAgent.py     \n",
      "  inflating: agents/QLearningAgent.py  \n",
      "   creating: agents/__pycache__/\n",
      "  inflating: agents/__pycache__/DQNNAgent.cpython-39.pyc  \n",
      "  inflating: agents/__pycache__/QLearningAgent.cpython-39.pyc  \n",
      "   creating: game/\n",
      "   creating: game/.mypy_cache/\n",
      " extracting: game/.mypy_cache/.gitignore  \n",
      "   creating: game/.mypy_cache/3.9/\n",
      " extracting: game/.mypy_cache/3.9/@plugins_snapshot.json  \n",
      "  inflating: game/.mypy_cache/3.9/_ast.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/_ast.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/_importlib_modulespec.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/_importlib_modulespec.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/_typeshed/\n",
      "  inflating: game/.mypy_cache/3.9/_typeshed/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/_typeshed/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/abc.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/abc.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/array.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/array.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/ast.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/ast.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/builtins.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/builtins.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/codecs.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/codecs.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/collections/\n",
      "  inflating: game/.mypy_cache/3.9/collections/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/collections/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/enum.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/enum.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/genericpath.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/genericpath.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/importlib/\n",
      "  inflating: game/.mypy_cache/3.9/importlib/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/importlib/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/importlib/abc.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/importlib/abc.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/inspect.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/inspect.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/io.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/io.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/matplotlib/\n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/artist.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/artist.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/axes.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/axes.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/backend_bases.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/backend_bases.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/cm.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/cm.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/collections.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/collections.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/color.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/color.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/font_manager.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/font_manager.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/image.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/image.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/legend.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/legend.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/patheffects.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/patheffects.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/pyplot.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/pyplot.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/style.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/style.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/text.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/text.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/transforms.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/matplotlib/transforms.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/mmap.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/mmap.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/numpy/\n",
      "  inflating: game/.mypy_cache/3.9/numpy/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/linalg.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/linalg.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/ma.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/ma.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/random.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/random.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/testing.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/numpy/testing.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/os/\n",
      "  inflating: game/.mypy_cache/3.9/os/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/os/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/os/path.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/os/path.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/__init__.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/core/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/__init__.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/core/arrays/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/base.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/base.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/integer.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/integer.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/masked.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/arrays/masked.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/core/dtypes/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/dtypes/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/dtypes/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/dtypes/base.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/dtypes/base.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/frame.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/frame.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/core/groupby/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/groupby/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/groupby/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/groupby/generic.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/groupby/generic.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pandas/core/indexes/\n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/base.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/base.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/frozen.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/frozen.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/multi.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexes/multi.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexing.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/indexing.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/series.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/series.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/strings.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/core/strings.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/testing.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pandas/testing.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pathlib.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pathlib.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/posix.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/posix.meta.json  \n",
      "   creating: game/.mypy_cache/3.9/pygame/\n",
      "  inflating: game/.mypy_cache/3.9/pygame/__init__.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/__init__.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/bufferproxy.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/bufferproxy.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/color.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/color.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/constants.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/constants.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/cursors.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/cursors.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/display.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/display.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/draw.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/draw.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/event.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/event.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/fastevent.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/fastevent.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/font.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/font.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/image.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/image.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/joystick.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/joystick.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/key.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/key.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mask.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mask.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/math.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/math.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mixer.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mixer.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mouse.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/mouse.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/music.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/music.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/pixelarray.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/pixelarray.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/pixelcopy.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/pixelcopy.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/rect.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/rect.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/scrap.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/scrap.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/sndarray.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/sndarray.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/sprite.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/sprite.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/surface.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/surface.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/surfarray.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/surfarray.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/time.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/time.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/transform.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/transform.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/version.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/pygame/version.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_compile.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_compile.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_constants.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_constants.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_parse.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/sre_parse.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/sys.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/sys.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/types.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/types.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/typing.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/typing.meta.json  \n",
      "  inflating: game/.mypy_cache/3.9/typing_extensions.data.json  \n",
      "  inflating: game/.mypy_cache/3.9/typing_extensions.meta.json  \n",
      "   creating: game/__pycache__/\n",
      "  inflating: game/__pycache__/missionariesandcannibals.cpython-39.pyc  \n",
      " extracting: game/boatt.png          \n",
      " extracting: game/canniball.png      \n",
      "  inflating: game/missionariesandcannibals.py  \n",
      " extracting: game/missionaryy.png    \n",
      "  inflating: game/riverr.png         \n",
      "  inflating: game/rysunek.svg        \n",
      "  inflating: play.py                 \n",
      "agents\tdrive  game  m.zip  play.py  sample_data\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1Y2OwZZzq5bjfWu3Vo3Par_auQxCGt6ze\n",
    "!unzip -n 'm.zip'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJLOPy-7rgHt"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/OM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWQl_M0-r0UZ",
    "outputId": "988d1948-3cf3-4171-dc32-f558d66e9b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/da/4ff439558641a26dd29b04c25947e6c0ace041f56b2aa2ef1134edab06b8/pygame-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8MB 245kB/s \n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.0.1\n",
      "pygame 2.0.1 (SDL 2.0.14, Python 3.6.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Surface(640x480x32 SW)>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pygame \n",
    "\n",
    "import os\n",
    "os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "import pygame\n",
    "pygame.display.set_mode((640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "wHu9470Xq-jn",
    "outputId": "f1de5027-e057-4b67-999d-c18a159571ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQNN\n",
      "Loading saved models' weights\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d416cd056aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading saved models' weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"online.tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"target.tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m         raise NotImplementedError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[1;32m   1336\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1337\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    965\u001b[0m           ._single_restoration_from_checkpoint_position(\n\u001b[1;32m    966\u001b[0m               \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m               visit_queue=visit_queue))\n\u001b[0m\u001b[1;32m    968\u001b[0m       \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       \u001b[0mtensor_saveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_single_restoration_from_checkpoint_position\u001b[0;34m(self, checkpoint_position, visit_queue)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                                []).append(child_position)\n\u001b[1;32m   1001\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mchild_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m           \u001b[0;31m# This object's correspondence is new, so dependencies need to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m           \u001b[0;31m# visited. Delay doing it so that we get a breadth-first dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mbind_object\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    305\u001b[0m                   proto_id=slot_restoration.slot_variable_id),\n\u001b[1;32m    306\u001b[0m               \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m               slot_name=slot_restoration.slot_name)\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# New assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_or_restore_slot_variable\u001b[0;34m(self, slot_variable_position, slot_name, variable)\u001b[0m\n\u001b[1;32m   1315\u001b[0m           \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m           slot_name=slot_name)\n\u001b[0m\u001b[1;32m   1318\u001b[0m       \u001b[0;31m# Slot variables are not owned by any one object (because we don't want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;31m# save the slot variable if the optimizer is saved without the non-slot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36madd_slot\u001b[0;34m(self, var, slot_name, initializer)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             initial_value=initial_value)\n\u001b[0m\u001b[1;32m    852\u001b[0m       \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0mslot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         shape=None):\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m       shape=shape)\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, shard_info)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# base_layer_utils.py's make_variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     return CheckpointInitialValue(\n\u001b[0;32m---> 82\u001b[0;31m         self._checkpoint_position, shape, shard_info=shard_info)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_position, shape, shard_info)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mshape_and_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     self.wrapped_value = checkpoint_position.value_tensors(\n\u001b[0;32m--> 113\u001b[0;31m         {VARIABLE_VALUE_KEY: shape_and_slice})[VARIABLE_VALUE_KEY]\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0;31m# We need to set the static shape information on the initializer if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mvalue_tensors\u001b[0;34m(self, shape_and_slices)\u001b[0m\n\u001b[1;32m    363\u001b[0m               \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_and_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m               \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m               name=\"%s_checkpoint_read\" % (serialized_tensor.name,))\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;31m# Copy the value to the current device if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mvalue_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mserialized_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1497\u001b[0m       return restore_v2_eager_fallback(\n\u001b[1;32m   1498\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1500\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0;32m-> 1537\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1538\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: TensorBundle at /content/drive/MyDrive/Colab Notebooks/OM/online.tf shard 0 (31668 bytes): Checksum does not match: stored 3128761256 vs. calculated on the restored bytes 879616768 [Op:RestoreV2]"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pygame\n",
    "from agents.QLearningAgent import QLearningAgent\n",
    "from agents.DQNNAgent import DDQNAgent\n",
    "from game.missionariesandcannibals import MnC\n",
    "import keras\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE\n",
    "import shutil\n",
    "\n",
    "# Possible algorithms are, 'Q-learning', 'DQNN'\n",
    "ALGORITHM = 'DQNN'\n",
    "DQNN_LEARN = True\n",
    "# ALGORITHM = 'Q-learning'\n",
    "\n",
    "env = MnC()\n",
    "env.reset()\n",
    "\n",
    "if ALGORITHM == 'Q-learning':\n",
    "    print(\"Q-learning\")\n",
    "    def play_and_train(env, agent):\n",
    "        \"\"\"\n",
    "        This function should\n",
    "        - run a full game, actions given by agent's e-greedy policy\n",
    "        - train agent using agent.update(...) whenever it is possible\n",
    "        - return total reward\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            agent.update(state, action, reward, next_state)    \n",
    "            state = next_state\n",
    "            if done:\n",
    "                break;\n",
    "        return total_reward\n",
    "\n",
    "    agent = QLearningAgent(alpha=0.01, epsilon=0.1, discount=0.99,\n",
    "                           get_legal_actions=env.get_possible_actions)\n",
    "    env.reset()\n",
    "    env.turn_off_display()\n",
    "    filtered_score_for_plotting = []\n",
    "    filtered_score = -500\n",
    "    theoretical_maximum = 500\n",
    "    total_iterations = 0\n",
    "    while filtered_score < theoretical_maximum:\n",
    "        iteration_counter = 0\n",
    "        while iteration_counter < 10:\n",
    "            iteration_counter += 1\n",
    "            score = play_and_train(env, agent)\n",
    "            filtered_score = 99/100 * filtered_score + 1/100 * score\n",
    "            print(theoretical_maximum, filtered_score)\n",
    "            filtered_score_for_plotting.append(filtered_score)\n",
    "        theoretical_maximum -= 0.1\n",
    "        total_iterations += iteration_counter\n",
    "    print(\"Stopped training with score \", theoretical_maximum, \" after \",\n",
    "            total_iterations, \" iterations.\")\n",
    "\n",
    "    plt.plot(filtered_score_for_plotting)\n",
    "    plt.ylabel(\"Filtered score\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    env.turn_on_display()\n",
    "    state = env.reset()\n",
    "    agent.turn_off_learning()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        score = 0\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, reward = env.step(action)\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        print(\"Score:\", reward)\n",
    "elif ALGORITHM == 'DQNN':\n",
    "    print(\"DQNN\")\n",
    "\n",
    "    translate = {}\n",
    "    translate[0] = 'm'\n",
    "    translate[1] = 'mm'\n",
    "    translate[2] = 'c'\n",
    "    translate[3] = 'cc'\n",
    "    translate[4] = 'cm'\n",
    "    translate['m'] = 0\n",
    "    translate['mm'] = 1\n",
    "    translate['c'] = 2\n",
    "    translate['cc'] = 3\n",
    "    translate['cm'] = 4\n",
    "\n",
    "    def translate_state(state: str) -> np.array:\n",
    "        new_state = [0] * 13\n",
    "        # 0 - strona po której jest łódka\n",
    "        # 1 - misjonarz po lewej stronie\n",
    "        # 2 - dwóch misjonarzy po lewej stronie\n",
    "        # 3 - trzech misjonarzy po lewej stronie\n",
    "        # 4 - kanibal po lewej stronie\n",
    "        # 5 - dwóch kanibali po lewej stronie\n",
    "        # 6 - trzech kanibali po lewej stronie\n",
    "        # 7 - misjonarz po prawej stronie\n",
    "        # 8 - dwóch misjonarzy po prawej stronie\n",
    "        # 9 - trzech misjonarzy po prawej stronie\n",
    "        # 10 - kanibal po prawej stronie\n",
    "        # 11 - dwóch kanibal po prawej stronie\n",
    "        # 12 - trzech kanibal po prawej stronie\n",
    "        boat = state.find('b')\n",
    "        river = state.find('-')\n",
    "        if boat < river:\n",
    "            new_state[0] = -1\n",
    "        else:\n",
    "            new_state[0] = 1\n",
    "        left_m = state.count('m', 0, river)\n",
    "        if left_m == 3:\n",
    "            new_state[3] = 1\n",
    "        elif left_m == 2:\n",
    "            new_state[2] = 1\n",
    "        elif left_m == 1:\n",
    "            new_state[1] = 1\n",
    "\n",
    "        left_c = state.count('c', 0, river)\n",
    "        if left_c == 3:\n",
    "            new_state[6] = 1\n",
    "        elif left_c == 2:\n",
    "            new_state[5] = 1\n",
    "        elif left_c == 1:\n",
    "            new_state[4] = 1\n",
    "\n",
    "        right_m = state.count('m', river)\n",
    "        if right_m == 3:\n",
    "            new_state[9] = 1\n",
    "        elif right_m == 2:\n",
    "            new_state[8] = 1\n",
    "        elif right_m == 1:\n",
    "            new_state[7] = 1\n",
    "\n",
    "        right_c = state.count('c', river)\n",
    "        if right_c == 3:\n",
    "            new_state[12] = 1\n",
    "        elif right_c == 2:\n",
    "            new_state[11] = 1\n",
    "        elif right_c == 1:\n",
    "            new_state[10] = 1\n",
    "\n",
    "        return np.reshape(np.array(new_state), -1)\n",
    "\n",
    "    def reverse_translate_state(state) -> str:\n",
    "        new_state = []\n",
    "\n",
    "        if state[0] == -1:\n",
    "            new_state.append('b')\n",
    "\n",
    "        if state[6] == 1:\n",
    "            new_state.append('ccc')\n",
    "        elif state[5] == 1:\n",
    "            new_state.append('cc')\n",
    "        elif state[4] == 1:\n",
    "            new_state.append('c')\n",
    "\n",
    "        if state[3] == 1:\n",
    "            new_state.append('mmm')\n",
    "        elif state[2] == 1:\n",
    "            new_state.append('mm')\n",
    "        elif state[1] == 1:\n",
    "            new_state.append('m')\n",
    "\n",
    "        new_state.append('-')\n",
    "        if state[0] == 1:\n",
    "            new_state.append('b')\n",
    "\n",
    "        if state[12] == 1:\n",
    "            new_state.append('ccc')\n",
    "        elif state[11] == 1:\n",
    "            new_state.append('cc')\n",
    "        elif state[10] == 1:\n",
    "            new_state.append('c')\n",
    "\n",
    "        if state[9] == 1:\n",
    "            new_state.append('mmm')\n",
    "        elif state[8] == 1:\n",
    "            new_state.append('mm')\n",
    "        elif state[7] == 1:\n",
    "            new_state.append('m')\n",
    "\n",
    "        return ''.join(map(str, new_state))\n",
    "\n",
    "    def get_illegal_actions(state):\n",
    "        state = reverse_translate_state(state)\n",
    "        legal = list(map(lambda x: translate[x], env.get_possible_actions(state)))\n",
    "        return [a for a in range(5) if a not in legal]\n",
    "\n",
    "    def build_model(initial_state, state_size, action_size):\n",
    "        keras.backend.clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=np.reshape(initial_state, (-1)).shape))\n",
    "        model.add(Dense(state_size ** (action_size / 2), activation='relu'))\n",
    "        model.add(Dense(state_size ** (action_size / 2), activation='relu'))\n",
    "        model.add(Dense(state_size ** (action_size / 2), activation='relu'))\n",
    "        model.add(Dense(state_size ** (action_size / 2), activation='relu'))\n",
    "        model.add(Dense(action_size))\n",
    "        model.compile(\n",
    "            loss=MSE,\n",
    "            optimizer=Adam(),\n",
    "        metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    agent = None\n",
    "    initial_state = env.reset()\n",
    "    translated_initial_state = translate_state(initial_state)\n",
    "\n",
    "    agent = DDQNAgent(action_size=5, state_size=len(translated_initial_state),\n",
    "            initial_state=translated_initial_state,\n",
    "            get_illegal_actions=get_illegal_actions,\n",
    "            build_model=build_model)\n",
    "\n",
    "    print(\"Loading saved models' weights\")\n",
    "    agent.online_model.load_weights(checkpoint_path + \"online.tf\")\n",
    "    agent.target_model.load_weights(checkpoint_path + \"target.tf\")\n",
    "\n",
    "    if DQNN_LEARN:\n",
    "        agent.epsilon = 0.222\n",
    "        agent.epsilon_min = 1/ (2 * 14)\n",
    "        agent.epsilon_decay = 0.9999 # 0.999\n",
    "        agent.learning_rate = 0.0001\n",
    "\n",
    "        done = False\n",
    "        batch_size = 256\n",
    "        episodes = 0\n",
    "        counter = 0\n",
    "\n",
    "        env.turn_off_display()\n",
    "\n",
    "        filtered_score_for_plotting = []\n",
    "        filtered_score = -500\n",
    "        theoretical_maximum = 500\n",
    "        episodes = 0\n",
    "        while filtered_score < theoretical_maximum:\n",
    "            episodes += 1\n",
    "            summary = []\n",
    "            for _ in range(100):\n",
    "                total_reward = 0\n",
    "                env_state = env.reset()\n",
    "\n",
    "                state = translate_state(env_state)\n",
    "\n",
    "                done = False\n",
    "                while not done:\n",
    "                    action = agent.get_action(state)\n",
    "                    env_action = translate[action]\n",
    "                    next_state_env, reward, done, score = env.step(env_action)\n",
    "                    total_reward += reward\n",
    "\n",
    "                    try:\n",
    "                        next_state = translate_state(next_state_env)\n",
    "                    except:\n",
    "                        # We hit a terminal state, no reason to bother translating\n",
    "                        print(state, next_state_env)\n",
    "                        next_state = state\n",
    "\n",
    "                    agent.remember(state, action, reward, next_state, done)\n",
    "                    state = next_state\n",
    "                filtered_score = 999/1000 * filtered_score + 1/1000 * score\n",
    "                filtered_score_for_plotting.append(filtered_score)\n",
    "                if len(agent.memory) > batch_size:\n",
    "                    agent.replay(batch_size)\n",
    "                \n",
    "                summary.append(total_reward)\n",
    "            theoretical_maximum -= 0.1\n",
    "            print(\"epoch #{},\\tfiltered_score = {},\\texpected reward = {:.3f}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(\n",
    "                episodes,\n",
    "                filtered_score,\n",
    "                theoretical_maximum,\n",
    "                np.mean(summary),\n",
    "                agent.epsilon))    \n",
    "            agent.update_epsilon_value()\n",
    "\n",
    "            shutil.copyfile(checkpoint_path + \"checkpoint\", checkpoint_path + \"backup_checkpoint\")\n",
    "            shutil.copyfile(checkpoint_path + \"online.tf.index\", checkpoint_path + \"backup_online.tf.index\")\n",
    "            shutil.copyfile(checkpoint_path + \"target.tf.index\", checkpoint_path + \"backup_target.tf.index\")\n",
    "            shutil.copyfile(checkpoint_path + \"online.tf.data-00000-of-00001\", checkpoint_path + \"backup_online.tf.data-00000-of-00001\")\n",
    "            shutil.copyfile(checkpoint_path + \"target.tf.data-00000-of-00001\", checkpoint_path + \"backup_target.tf.data-00000-of-00001\")\n",
    "            agent.online_model.save_weights(checkpoint_path + \"online.tf\", save_format='tf')\n",
    "            agent.target_model.save_weights(checkpoint_path + \"target.tf\", save_format='tf')\n",
    "\n",
    "        plt.plot(filtered_score_for_plotting)\n",
    "        plt.ylabel(\"Filtered score\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No algorithm selected\")\n",
    "print(\"Done, download the models.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MnC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
